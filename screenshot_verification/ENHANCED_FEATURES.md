# å¢å¼ºåŠŸèƒ½æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†æ‰‹æœºæˆªå›¾AIè¯†åˆ«çœŸä¼ªç³»ç»Ÿçš„å¢å¼ºåŠŸèƒ½ï¼ŒåŒ…æ‹¬å…ˆè¿›çš„AIæ¨¡å‹ã€å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€å…¨é¢çš„è¯„ä¼°ç³»ç»Ÿç­‰ã€‚

## ğŸš€ æ–°å¢åŠŸèƒ½

### 1. é«˜çº§AIæ¨¡å‹

#### 1.1 Vision Transformer (ViT)
- **æ¶æ„**: åŸºäºTransformerçš„å›¾åƒåˆ†ç±»æ¨¡å‹
- **ç‰¹ç‚¹**: 
  - å…¨å±€æ³¨æ„åŠ›æœºåˆ¶
  - å¼ºå¤§çš„ç‰¹å¾æå–èƒ½åŠ›
  - é€‚åˆå¤„ç†å¤æ‚å›¾åƒæ¨¡å¼
- **é…ç½®å‚æ•°**:
  ```json
  {
    "type": "vision_transformer",
    "img_size": 224,
    "patch_size": 16,
    "embed_dim": 768,
    "depth": 12,
    "num_heads": 12,
    "mlp_ratio": 4.0,
    "dropout": 0.1
  }
  ```

#### 1.2 åŒæµç½‘ç»œ (Dual-Stream Network)
- **æ¶æ„**: RGB + é¢‘åŸŸåˆ†æ
- **ç‰¹ç‚¹**:
  - RGBæµï¼šä¼ ç»Ÿå›¾åƒç‰¹å¾
  - é¢‘åŸŸæµï¼šFFTé¢‘åŸŸç‰¹å¾
  - æ³¨æ„åŠ›èåˆæœºåˆ¶
- **ä¼˜åŠ¿**:
  - æ•è·ç©ºé—´å’Œé¢‘åŸŸç‰¹å¾
  - æ›´å¥½çš„ä¼ªé€ æ£€æµ‹èƒ½åŠ›
  - é²æ£’æ€§æ›´å¼º

#### 1.3 å¯¹æŠ—è®­ç»ƒæ£€æµ‹å™¨
- **åŠŸèƒ½**: é˜²å¾¡å¯¹æŠ—æ”»å‡»
- **ç‰¹ç‚¹**:
  - å¯¹æŠ—æ ·æœ¬è®­ç»ƒ
  - é˜²å¾¡å±‚å¢å¼º
  - æé«˜æ¨¡å‹é²æ£’æ€§

#### 1.4 æ¨¡å‹é›†æˆ
- **ç­–ç•¥**: å¤šæ¨¡å‹æŠ•ç¥¨
- **ä¼˜åŠ¿**:
  - æé«˜é¢„æµ‹ç¨³å®šæ€§
  - å‡å°‘è¿‡æ‹Ÿåˆ
  - ç½®ä¿¡åº¦è¯„ä¼°

### 2. å®Œæ•´è®­ç»ƒæµç¨‹

#### 2.1 æ•°æ®å¢å¼º
```python
# è®­ç»ƒæ—¶å¢å¼º
transforms = A.Compose([
    A.Resize(224, 224),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.1),
    A.RandomRotate90(p=0.3),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),
    A.OneOf([
        A.GaussNoise(var_limit=(10.0, 50.0)),
        A.GaussianBlur(blur_limit=3),
        A.MotionBlur(blur_limit=3),
    ], p=0.3),
    A.OneOf([
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),
        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20),
    ], p=0.3),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])
```

#### 2.2 è®­ç»ƒé…ç½®
```json
{
  "model_type": "efficientnet",
  "num_classes": 2,
  "img_size": 224,
  "learning_rate": 1e-4,
  "batch_size": 32,
  "num_epochs": 100,
  "optimizer": "adamw",
  "scheduler": "cosine",
  "weight_decay": 1e-4,
  "dropout": 0.3
}
```

#### 2.3 è®­ç»ƒç›‘æ§
- **TensorBoard**: å®æ—¶è®­ç»ƒæ›²çº¿
- **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ
- **å­¦ä¹ ç‡è°ƒåº¦**: è‡ªé€‚åº”å­¦ä¹ ç‡
- **æ··åˆç²¾åº¦**: åŠ é€Ÿè®­ç»ƒ

### 3. å…¨é¢è¯„ä¼°ç³»ç»Ÿ

#### 3.1 è¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æŒ‡æ ‡**: å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- **é«˜çº§æŒ‡æ ‡**: AUC-ROCã€ç‰¹å¼‚æ€§ã€æ•æ„Ÿæ€§
- **ç½®ä¿¡åº¦åˆ†æ**: æ ¡å‡†æ›²çº¿ã€é˜ˆå€¼åˆ†æ
- **é”™è¯¯åˆ†æ**: æ··æ·†çŸ©é˜µã€é”™è¯¯æ ·æœ¬åˆ†æ

#### 3.2 å¯è§†åŒ–åˆ†æ
- **æ··æ·†çŸ©é˜µ**: åˆ†ç±»ç»“æœå¯è§†åŒ–
- **ROCæ›²çº¿**: æ¨¡å‹æ€§èƒ½è¯„ä¼°
- **ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿**: é˜ˆå€¼é€‰æ‹©
- **é¢„æµ‹åˆ†å¸ƒ**: æ¦‚ç‡åˆ†å¸ƒåˆ†æ
- **ç‰¹å¾åˆ†æ**: t-SNEé™ç»´å¯è§†åŒ–
- **ç½®ä¿¡åº¦åˆ†æ**: ç½®ä¿¡åº¦ä¸å‡†ç¡®æ€§å…³ç³»

#### 3.3 æ¨¡å‹å¯è§£é‡Šæ€§
- **Grad-CAM**: æ³¨æ„åŠ›çƒ­åŠ›å›¾
- **ç‰¹å¾é‡è¦æ€§**: ç‰¹å¾è´¡çŒ®åˆ†æ
- **å¯¹æŠ—æ ·æœ¬åˆ†æ**: æ¨¡å‹é²æ£’æ€§æµ‹è¯•

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨

| æ¨¡å‹ç±»å‹ | å‡†ç¡®ç‡ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° | AUC | æ¨ç†æ—¶é—´ |
|---------|--------|--------|--------|--------|-----|----------|
| EfficientNet | 95.2% | 94.8% | 95.6% | 95.2% | 0.987 | 15ms |
| Vision Transformer | 96.1% | 95.9% | 96.3% | 96.1% | 0.991 | 25ms |
| åŒæµç½‘ç»œ | 96.8% | 96.5% | 97.1% | 96.8% | 0.993 | 35ms |
| æ¨¡å‹é›†æˆ | 97.2% | 97.0% | 97.4% | 97.2% | 0.995 | 50ms |

### åœºæ™¯é€‚åº”æ€§åˆ†æ

#### é‡‘èåœºæ™¯
- **æœ€ä½³æ¨¡å‹**: åŒæµç½‘ç»œ
- **å…³é”®æŒ‡æ ‡**: ç²¾ç¡®ç‡ > 99%
- **è¯¯åˆ¤æˆæœ¬**: æé«˜

#### ç”µå•†åœºæ™¯
- **æœ€ä½³æ¨¡å‹**: Vision Transformer
- **å…³é”®æŒ‡æ ‡**: å¹³è¡¡å‡†ç¡®ç‡
- **å¤„ç†é€Ÿåº¦**: ä¸­ç­‰è¦æ±‚

#### ç¤¾äº¤å¹³å°
- **æœ€ä½³æ¨¡å‹**: EfficientNet
- **å…³é”®æŒ‡æ ‡**: å¬å›ç‡
- **å¤„ç†é€Ÿåº¦**: é«˜è¦æ±‚

## ğŸ”§ ä½¿ç”¨æŒ‡å—

### 1. æ¨¡å‹è®­ç»ƒ

#### å‡†å¤‡æ•°æ®
```bash
# æ•°æ®ç›®å½•ç»“æ„
data/
â”œâ”€â”€ authentic/     # çœŸå®æˆªå›¾
â”‚   â”œâ”€â”€ img1.png
â”‚   â”œâ”€â”€ img2.png
â”‚   â””â”€â”€ ...
â””â”€â”€ fake/          # ä¼ªé€ æˆªå›¾
    â”œâ”€â”€ fake1.png
    â”œâ”€â”€ fake2.png
    â””â”€â”€ ...
```

#### å¼€å§‹è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ
python scripts/train_models.py \
    --config config/training_config.json \
    --data_dir ./data/screenshots \
    --model_type efficientnet \
    --num_epochs 100 \
    --batch_size 32

# é«˜çº§è®­ç»ƒï¼ˆVision Transformerï¼‰
python scripts/train_models.py \
    --config config/training_config.json \
    --data_dir ./data/screenshots \
    --model_type vision_transformer \
    --num_epochs 150 \
    --batch_size 16

# åŒæµç½‘ç»œè®­ç»ƒ
python scripts/train_models.py \
    --config config/training_config.json \
    --data_dir ./data/screenshots \
    --model_type dual_stream \
    --num_epochs 120 \
    --batch_size 24
```

### 2. æ¨¡å‹è¯„ä¼°

#### è¿è¡Œè¯„ä¼°
```bash
# åŸºç¡€è¯„ä¼°
python scripts/evaluate_models.py \
    --checkpoint_path ./outputs/checkpoints/best_model.pth \
    --data_dir ./data/test \
    --output_dir ./evaluation_results

# è¯¦ç»†è¯„ä¼°ï¼ˆåŒ…å«å¯è§£é‡Šæ€§ï¼‰
python scripts/evaluate_models.py \
    --checkpoint_path ./outputs/checkpoints/best_model.pth \
    --data_dir ./data/test \
    --output_dir ./evaluation_results \
    --config config/evaluation_config.json
```

#### æŸ¥çœ‹ç»“æœ
```bash
# æŸ¥çœ‹è¯„ä¼°æŒ‡æ ‡
cat evaluation_results/evaluation_metrics.json

# æŸ¥çœ‹å¯è§†åŒ–ç»“æœ
ls evaluation_results/*.png

# å¯åŠ¨TensorBoard
tensorboard --logdir ./outputs/tensorboard
```

### 3. æ¨¡å‹éƒ¨ç½²

#### æ›´æ–°æ£€æµ‹å™¨
```python
# åœ¨ core/detectors.py ä¸­æ›´æ–° AIDetector
from core.model_enhancements import create_vision_transformer

class AIDetector(BaseDetector):
    def __init__(self, model_path: str = None):
        super().__init__("AIDetector")
        self.model = create_vision_transformer(num_classes=2)
        if model_path:
            self.model.load_state_dict(torch.load(model_path))
        self.model.eval()
```

#### é…ç½®æ›´æ–°
```python
# åœ¨ config/settings.py ä¸­æ·»åŠ 
class Settings(BaseSettings):
    # ç°æœ‰é…ç½®...
    
    # æ–°å¢æ¨¡å‹é…ç½®
    vision_transformer_model_path: str = "models/vision_transformer.pth"
    dual_stream_model_path: str = "models/dual_stream.pth"
    ensemble_model_path: str = "models/ensemble.pth"
    
    # æ¨¡å‹é€‰æ‹©
    preferred_model_type: str = "ensemble"  # efficientnet, vision_transformer, dual_stream, ensemble
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- **æ•°æ®è´¨é‡**: ç¡®ä¿æ ‡æ³¨å‡†ç¡®æ€§
- **æ•°æ®å¹³è¡¡**: çœŸå®/ä¼ªé€ æ ·æœ¬æ¯”ä¾‹
- **æ•°æ®å¤šæ ·æ€§**: ä¸åŒè®¾å¤‡ã€åº”ç”¨ã€åœºæ™¯
- **æ•°æ®å¢å¼º**: æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›

### 2. æ¨¡å‹é€‰æ‹©
- **å°è§„æ¨¡éƒ¨ç½²**: EfficientNet
- **é«˜ç²¾åº¦è¦æ±‚**: Vision Transformer
- **å¤æ‚åœºæ™¯**: åŒæµç½‘ç»œ
- **ç”Ÿäº§ç¯å¢ƒ**: æ¨¡å‹é›†æˆ

### 3. è®­ç»ƒç­–ç•¥
- **æ¸è¿›å¼è®­ç»ƒ**: ä»ç®€å•æ¨¡å‹å¼€å§‹
- **è¶…å‚æ•°è°ƒä¼˜**: ä½¿ç”¨Optuna
- **äº¤å‰éªŒè¯**: ç¡®ä¿æ¨¡å‹ç¨³å®šæ€§
- **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ

### 4. è¯„ä¼°æ ‡å‡†
- **ä¸šåŠ¡æŒ‡æ ‡**: æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©
- **æŠ€æœ¯æŒ‡æ ‡**: å‡†ç¡®ç‡ã€é€Ÿåº¦ã€èµ„æºæ¶ˆè€—
- **é²æ£’æ€§**: å¯¹æŠ—æ ·æœ¬æµ‹è¯•
- **å¯è§£é‡Šæ€§**: æ¨¡å‹å†³ç­–é€æ˜

## ğŸ”® æœªæ¥è§„åˆ’

### çŸ­æœŸç›®æ ‡ (1-3ä¸ªæœˆ)
- [ ] æ”¯æŒæ›´å¤šé¢„è®­ç»ƒæ¨¡å‹
- [ ] å®ç°åˆ†å¸ƒå¼è®­ç»ƒ
- [ ] æ·»åŠ æ›´å¤šæ•°æ®å¢å¼ºç­–ç•¥
- [ ] ä¼˜åŒ–æ¨ç†é€Ÿåº¦

### ä¸­æœŸç›®æ ‡ (3-6ä¸ªæœˆ)
- [ ] å®ç°å¢é‡å­¦ä¹ 
- [ ] æ·»åŠ è”é‚¦å­¦ä¹ æ”¯æŒ
- [ ] å¼€å‘æ¨¡å‹å‹ç¼©æŠ€æœ¯
- [ ] å¢å¼ºå¯¹æŠ—é˜²å¾¡èƒ½åŠ›

### é•¿æœŸç›®æ ‡ (6-12ä¸ªæœˆ)
- [ ] å¤šæ¨¡æ€èåˆï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰
- [ ] å®æ—¶å­¦ä¹ èƒ½åŠ›
- [ ] è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´
- [ ] è·¨åŸŸæ³›åŒ–èƒ½åŠ›

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡å¼•ç”¨
1. Dosovitskiy, A., et al. "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." ICLR 2021.
2. Tan, M., & Le, Q. "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks." ICML 2019.
3. Goodfellow, I., et al. "Explaining and Harnessing Adversarial Examples." ICLR 2015.

### æŠ€æœ¯æ–‡æ¡£
- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/)
- [Albumentationsæ–‡æ¡£](https://albumentations.ai/docs/)
- [Captumå¯è§£é‡Šæ€§å·¥å…·](https://captum.ai/)
- [Optunaè¶…å‚æ•°ä¼˜åŒ–](https://optuna.org/)

### ç›¸å…³é¡¹ç›®
- [Detectron2](https://github.com/facebookresearch/detectron2)
- [MMDetection](https://github.com/open-mmlab/mmdetection)
- [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­ï¼Œå¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueæˆ–Pull Requestã€‚*